---
lang: fr
format:
    html:
        link-external-newwindow: true
---
## 2.1 - Quelques histoires {#sec-short_stories}

Nous commencerons avec quelques courtes histoires. Chaque histoire est un appel volontairement exagéré pour un apprentissage automatique interprétable. Si vous êtes pressé, vous pouvez les passer. Si vous voulez être diverti et (dé)motivé, poursuivez leur lecture !

Le format est inspiré par les "Tech Tales" de Jack Clark dans sa [Newsletter Import AI](https://jack-clark.net/). Si vous aimez ce genre d'histoires ou si vous vous intéressez à l'IA, je vous recommande de vous inscrire.


### 2.1.1 - La foudre ne frappe jamais deux fois
**2030: Un laboratoire médical en Suisse**

![hospital](../_static/images/hospital.png){width=400px align=center}

"Il n'y a certainement pas pire façon de mourir !" résuma Tom, essayant de trouver quelque chose de positif dans la tragédie.
Il retira la pompe de la perfusion.
"Il est juste mort pour de mauvaises raisons," ajouta Lena.
"Et certainement avec la mauvaise pompe à morphine ! Cela crée juste plus de travail pour nous !" se plaignit Tom en dévissant le panneau arrière de la pompe. Après avoir retiré toutes les vis, il souleva le panneau et le mit de côté. Il brancha un câble sur le port de diagnostic. "Tu ne te plaignais pas d'avoir un travail, n'est-ce pas ?" Lena lui lança un sourire moqueur. "Bien sûr que non. Jamais !" s'exclama-t-il avec un ton sarcastique.

Il démarra l'ordinateur de la pompe. Lena brancha l'autre extrémité du câble à sa tablette. "Bon, le diagnostic est en cours," annonça-t-elle. "Je suis vraiment curieuse de savoir ce qui a mal tourné." "Ça a certainement envoyé notre John Doe au Nirvana. Cette haute concentration de ce truc à la morphine. Mec. Je veux dire... c'est une première, non ? Normalement, une pompe cassée donne trop peu de la douce substance ou rien du tout. Mais jamais, tu sais, comme cette folle injection," expliqua Tom. "Je sais. Tu n'as pas à me convaincre... Hey, regarde ça." Lena leva sa tablette. "Tu vois ce pic ici ? C'est la puissance du mélange d'antidouleurs. Regarde ! Cette ligne montre le niveau de référence. Le pauvre gars avait un mélange d'antidouleurs dans son système sanguin qui aurait pu le tuer 17 fois. Injecté par notre pompe ici. Et ici..." elle fit glisser, "ici tu peux voir le moment de la mort du patient." "Alors, une idée de ce qui s'est passé, chef ?" demanda Tom à son superviseur. "Hm... Les capteurs semblent être bons. Rythme cardiaque, niveaux d'oxygène, glucose,... Les données ont été collectées comme prévu. Quelques valeurs manquantes dans les données d'oxygène sanguin, mais ce n'est pas inhabituel. Regarde ici. Les capteurs ont également détecté le ralentissement du rythme cardiaque du patient et des niveaux extrêmement bas de cortisol causés par le dérivé de morphine et d'autres agents bloquant la douleur." Elle continua de faire défiler le rapport de diagnostic. Tom était captivé par l'écran. C'était sa première enquête sur une véritable défaillance d'appareil.

"Ok, voici notre premier élément du puzzle. Le système a échoué à envoyer un avertissement au canal de communication de l'hôpital. L'avertissement a été déclenché, mais rejeté au niveau du protocole. Cela pourrait être de notre faute, mais cela pourrait aussi être la faute de l'hôpital. S'il te plaît, envoie les journaux à l'équipe informatique," dit Lena à Tom. Tom acquiesça, les yeux toujours fixés sur l'écran. Lena continua : "C'est étrange. L'avertissement aurait également dû provoquer l'arrêt de la pompe. Mais il a manifestement échoué à le faire. Cela doit être un bug. Quelque chose que l'équipe qualité a manqué. Quelque chose de vraiment mauvais. Peut-être que c'est lié au problème de protocole." "Donc, le système d'urgence de la pompe a d'une manière ou d'une autre été rompu, mais pourquoi la pompe est-elle devenue folle et a injecté autant d'antidouleurs dans John Doe ?" se demanda Tom. "Bonne question. Tu as raison. Même en cas de défaillance de l'urgence du protocole, la pompe n'aurait pas dû administrer autant de médicament. L'algorithme aurait dû s'arrêter bien plus tôt de lui-même, étant donné le faible niveau de cortisol et d'autres signes d'alerte," expliqua Lena. "Peut-être un coup de malchance, comme une chose sur un million, comme être frappé par la foudre ?" demanda Tom. "Non, Tom. Si tu avais lu la documentation que je t'ai envoyée, tu aurais su que la pompe a d'abord été entraînée dans des expériences sur des animaux, puis plus tard sur des humains, pour apprendre à injecter la quantité parfaite d'antidouleurs en fonction des entrées sensorielles. L'algorithme de la pompe peut être opaque et complexe, mais il n'est pas aléatoire. Cela signifie que dans la même situation, la pompe se comporterait exactement de la même manière à nouveau. Notre patient mourrait à nouveau. Une combinaison ou une interaction indésirable des entrées sensorielles doit avoir déclenché le comportement erroné de la pompe. C'est pourquoi nous devons creuser plus profondément et découvrir ce qui s'est passé ici," expliqua Lena.

"Je vois...," répondit Tom, perdu dans ses pensées. "Le patient n'allait-il pas mourir bientôt de toute façon ? À cause du cancer ou de quelque chose ?" Lena hocha la tête en lisant le rapport d'analyse. Tom se leva et alla à la fenêtre. Il regarda dehors, les yeux fixés sur un point au loin. "Peut-être que la machine lui a rendu service, tu sais, en le libérant de la douleur. Plus de souffrance. Peut-être qu'elle a juste fait ce qu'il fallait. Comme la foudre, mais, tu sais, une bonne. Je veux dire comme la loterie, mais pas aléatoire. Mais pour une raison. Si j'étais la pompe, j'aurais fait la même chose." Elle finalement leva la tête et le regarda. Il continuait de regarder quelque chose à l'extérieur. Tous deux restèrent silencieux quelques instants. Lena baissa à nouveau la tête et continua l'analyse. "Non, Tom. C'est un bug... Juste un sacré bug."
<!--
"It's definitely not the worst way to die!" Tom summarised, trying to find something positive in the tragedy.
He removed the pump from the intravenous pole.   
"He just died for the wrong reasons," Lena added.  
"And certainly with the wrong morphine pump!
Just creating more work for us!" Tom complained while unscrewing the back plate of the pump.
After removing all the screws, he lifted the plate and put it aside.
He plugged a cable into the diagnostic port.   
"You didn't just complain about having a job, did you?" Lena gave him a mocking smile.  
"Of course not. Never!" he exclaimed with a sarcastic undertone.

He booted the pump's computer.  
Lena plugged the other end of the cable into her tablet.
"All right, diagnostics are running," she announced.
"I am really curious about what went wrong."  
"It certainly shot our John Doe into Nirvana.
That high concentration of this morphine stuff.
Man. I mean ... that's a first, right?
Normally a broken pump gives off too little of the sweet stuff or nothing at all.
But never, you know, like that crazy shot," Tom explained.  
"I know. You don't have to convince me ... Hey, look at that." Lena held up her tablet.
"Do you see this peak here? That's the potency of the painkillers mix.
Look! This line shows the reference level.
The poor guy had a mixture of painkillers in his blood system that could kill him 17 times over.
Injected by our pump here.
And here ..." she swiped, "here you can see the moment of the patient's demise."  
"So, any idea what happened, boss?" Tom asked his supervisor.  
"Hm ... The sensors seem to be fine.
Heart rate, oxygen levels, glucose, ... The data were collected as expected.
Some missing values in the blood oxygen data, but that's not unusual.
Look here.
The sensors have also detected the patient's slowing heart rate and extremely low cortisol levels caused by the morphine derivate and other pain blocking agents."
She continued to swipe through the diagnostics report.  
Tom stared captivated at the screen.
It was his first investigation of a real device failure.

"Ok, here is our first piece of the puzzle.
The system failed to send a warning to the hospital's communication channel.
The warning was triggered, but rejected at protocol level.
It could be our fault, but it could also be the fault of the hospital.
Please send the logs over to the IT team," Lena told Tom.  
Tom nodded with his eyes still fixed on the screen.  
Lena continued:
"It's odd.
The warning should also have caused the pump to shut down.
But it obviously failed to do so.
That must be a bug.
Something the quality team missed.
Something really bad.
Maybe it's related to the protocol issue."  
"So, the emergency system of the pump somehow broke down, but why did the pump go full bananas and inject so much painkiller into John Doe?" Tom wondered.  
"Good question.
You are right.
Protocol emergency failure aside, the pump shouldn't have administered that amount of medication at all.
The algorithm should have stopped much earlier on its own, given the low level of cortisol and other warning signs," Lena explained.  
"Maybe some bad luck, like a one in a million thing, like being hit by a lightning?" Tom asked her.  
"No, Tom.
If you had read the documentation I sent you, you would have known that the pump was first trained in animal experiments, then later on humans, to learn to inject the perfect amount of painkillers based on the sensory input.
The algorithm of the pump might be opaque and complex, but it's not random.
That means that in the same situation the pump would behave exactly the same way again.
Our patient would die again.
A combination or undesired interaction of the sensory inputs must have triggered the erroneous behavior of the pump.
That is why we have to dig deeper and find out what happened here," Lena explained.

"I see ...," Tom replied, lost in thought.
"Wasn't the patient going to die soon anyway? Because of cancer or something?"  
Lena nodded while she read the analysis report.  
Tom got up and went to the window.
He looked outside, his eyes fixed on a point in the distance.
"Maybe the machine did him a favor, you know, in freeing him from the pain.
No more suffering.
Maybe it just did the right thing.
Like a lightning, but, you know, a good one. 
I mean like the lottery, but not random. 
But for a reason.
If I were the pump, I would have done the same."  
She finally lifted her head and looked at him.  
He kept looking at something outside.  
Both were silent for a few moments.   
Lena lowered her head again and continued the analysis.
"No, Tom. It's a bug... Just a damn bug."
-->

### 2.1.2 - Perte de confiance
**2050: Une station de métro à Singapour**

![access-denied](../_static/images/access-denied.jpg){width=400px align=center}

Elle se précipita vers la station de métro Bishan. Ses pensées étaient déjà au travail. Les tests pour la nouvelle architecture neuronale devraient être terminés maintenant. Elle dirigeait la refonte du "Système de Prédiction de l'Affinité Fiscale pour les Entités Individuelles" du gouvernement, qui prédit si une personne cachera de l'argent au bureau des impôts. Son équipe a conçu une pièce d'ingénierie élégante. Si réussi, le système servirait non seulement l'administration fiscale, mais alimenterait également d'autres systèmes tels que le système d'alerte antiterroriste et le registre commercial. Un jour, le gouvernement pourrait même intégrer les prédictions dans le Score de Confiance Civique. Le Score de Confiance Civique estime la fiabilité d'une personne. Cette estimation affecte chaque aspect de votre vie quotidienne, comme obtenir un prêt ou le temps d'attente pour un nouveau passeport. Alors qu'elle descendait l'escalator, elle imaginait à quoi pourrait ressembler l'intégration du système de son équipe dans le Système de Score de Confiance Civique.

Elle essuya machinalement sa main sur le lecteur RFID sans réduire sa vitesse de marche. Son esprit était occupé, mais une dissonance entre les attentes sensorielles et la réalité sonna l'alarme dans son cerveau.

Trop tard.

Elle se cogna le nez contre le portillon d'entrée du métro et tomba sur les fesses au sol. La porte aurait dû s'ouvrir, ... mais elle ne l'a pas fait. Abasourdie, elle se leva et regarda l'écran à côté du portillon. "Veuillez réessayer plus tard," suggéra un smiley à l'air sympathique sur l'écran. Une personne passa à côté d'elle et, sans lui prêter attention, essuya sa main sur le lecteur. La porte s'ouvrit et il passa. La porte se referma. Elle essuya son nez. Ça faisait mal, mais au moins ça ne saignait pas. Elle tenta d'ouvrir la porte, mais fut à nouveau rejetée. C'était étrange. Peut-être que son compte de transport public n'avait pas assez de jetons. Elle regarda sa montre intelligente pour vérifier le solde du compte.

"Connexion refusée. Veuillez contacter votre Bureau de Conseil aux Citoyens !" l'informa sa montre.

Un sentiment de nausée la frappa comme un coup de poing dans l'estomac. Elle soupçonnait ce qui s'était passé. Pour confirmer sa théorie, elle lança le jeu mobile "Sniper Guild", un jeu de tir à la première personne. L'application se ferma automatiquement, ce qui confirma sa théorie. Elle devint étourdie et s'assit à nouveau sur le sol.

Il n'y avait qu'une seule explication possible : Son Score de Confiance Civique avait chuté. Substantiellement. Une petite baisse signifiait des désagréments mineurs, comme ne pas obtenir de vols en première classe ou devoir attendre un peu plus longtemps pour les documents officiels. Un score de confiance faible était rare et signifiait que vous étiez classé comme une menace pour la société. Une mesure pour traiter ces personnes était de les éloigner des lieux publics tels que le métro. Le gouvernement restreignait les transactions financières des sujets avec de faibles Scores de Confiance Civique. Ils commençaient également à surveiller activement votre comportement sur les réseaux sociaux et allaient même jusqu'à restreindre certains contenus, comme les jeux violents. Il devenait exponentiellement plus difficile d'augmenter votre Score de Confiance Civique plus il était bas. Les personnes avec un score très faible ne se rétablissaient généralement jamais.

Elle ne pouvait penser à aucune raison pour laquelle son score aurait dû chuter. Le score était basé sur l'apprentissage automatique. Le Système de Score de Confiance Civique fonctionnait comme un moteur bien huilé qui réglait la société. La performance du Système de Score de Confiance était toujours étroitement surveillée. L'apprentissage automatique était devenu bien meilleur depuis le début du siècle. Il était devenu si efficace que les décisions prises par le Système de Score de Confiance ne pouvaient plus être contestées. Un système infaillible.

Elle rit dans le désespoir. Système infaillible. Si seulement. Le système a rarement échoué. Mais il a échoué. Elle doit être l'un de ces cas spéciaux ; une erreur du système ; désormais une paria. Personne n'osait remettre en question le système. Il était trop intégré dans le gouvernement, dans la société elle-même, pour être remis en question. Dans les quelques pays démocratiques restants, il était interdit de former des mouvements antidémocratiques, non parce qu'ils étaient intrinsèquement malveillants, mais parce qu'ils déstabiliseraient le système actuel. La même logique s'appliquait aux algocraties désormais plus courantes. La critique des algorithmes était interdite en raison du danger pour le statu quo.

La confiance algorithmique était le tissu de l'ordre social. Pour le bien commun, les fausses notations de confiance rares étaient tacitement acceptées. Des centaines d'autres systèmes de prédiction et de bases de données alimentaient le score, rendant impossible de savoir ce qui a causé la chute de son score. Elle se sentait comme si un grand trou noir s'ouvrait en elle et sous elle. Avec horreur, elle regarda dans le vide.

Son système d'affinité fiscale a finalement été intégré dans le Système de Score de Confiance Civique, mais elle n'a jamais pu le savoir.

<!--
She rushed to the Bishan subway station.
With her thoughts she was already at work.
The tests for the new neural architecture should be completed by now.
She led the redesign of the government's "Tax Affinity Prediction System for Individual Entities", which predicts whether a person will hide money from the tax office.
Her team has come up with an elegant piece of engineering.
If successful, the system would not only serve the tax office, but also feed into other systems such as the counter-terrorism alarm system and the commercial registry.
One day, the government could even integrate the predictions into the Civic Trust Score.
The Civic Trust Score estimates how trustworthy a person is. 
The estimate affects every part of your daily life, such as getting a loan or how long you have to wait for a new passport.
As she descended the escalator, she imagined how an integration of her team's system into the Civic Trust Score System might look like.

She routinely wiped her hand over the RFID reader without reducing her walking speed.
Her mind was occupied, but a dissonance of sensory expectations and reality rang alarm bells in her brain.

Too late.

Nose first she ran into the subway entrance gate and fell with her butt first to the ground.
The door was supposed to open, ... but it did not.
Dumbfounded, she stood up and looked at the screen next to the gate.
"Please try another time," suggested a friendly looking smiley on the screen.
A person passed by and, ignoring her, wiped his hand over the reader.
The door opened and he went through.
The door closed again.
She wiped her nose.
It hurt, but at least it did not bleed.
She tried to open the door, but was rejected again.
It was strange.
Maybe her public transport account did not have sufficient tokens.
She looked at her smartwatch to check the account balance.

"Login denied. Please contact your Citizens Advice Bureau!" her watch informed her.

A feeling of nausea hit her like a fist to the stomach.
She suspected what had happened.
To confirm her theory, she started the mobile game "Sniper Guild", an ego shooter.
The app was directly closed again automatically, which confirmed her theory.
She became dizzy and sat down on the floor again.

There was only one possible explanation:
Her Civic Trust Score had dropped. 
Substantially.
A small drop meant minor inconveniences, such as not getting first class flights or having to wait a little longer for official documents.
A low trust score was rare and meant that you were classified as a threat to society.
One measure in dealing with these people was to keep them away from public places such as the subway.
The government restricted the financial transactions of subjects with low Civic Trust Scores.
They also began to actively monitor your behavior on social media and even went as far as to restrict certain content, such as violent games.
It became exponentially more difficult to increase your Civic Trust Score the lower it was.
People with a very low score usually never recovered.

She could not think of any reason why her score should have fallen.
The score was based on machine learning.
The Civic Trust Score System worked like a well-oiled engine that ran society.
The performance of the Trust Score System was always closely monitored.
Machine learning had become much better since the beginning of the century.
It had become so efficient that decisions made by the Trust Score System could no longer be disputed.
An infallible system.

She laughed in despair.
Infallible system.
If only.
The system has rarely failed.
But it failed.
She must be one of those special cases;
an error of the system;
from now on an outcast.
Nobody dared to question the system.
It was too integrated into the government, into society itself, to be questioned.
In the few remaining democratic countries it was forbidden to form anti-democratic movements, not because they where inherently malicious, but because they would destabilize the current system.
The same logic applied to the now more common algocraties.
Critique in the algorithms was forbidden because of the danger to the status quo.

Algorithmic trust was the fabric of the social order.
For the common good, rare false trust scorings were tacitly accepted.
Hundreds of other prediction systems and databases fed into the score, making it impossible to know what caused the drop in her score.
She felt like a big dark hole was opening in and under her.
With horror she looked into the void.

Her tax affinity system was eventually integrated into the Civic Trust Score System, but she never got to know it.
-->


### 2.1.3 - Les trombones de Fermi
**Année 612 ACM (Après Colonisation de Mars): Un musée sur Mars**

![burnt-earth](../_static/images/burnt-earth.jpg){width=400px align=center}

"L'histoire, c'est ennuyeux," murmura Xola à son amie. Xola, une fille aux cheveux bleus, chassait paresseusement l'un des drones projecteurs bourdonnant dans la salle avec sa main gauche. "L'histoire est importante," dit le professeur d'une voix contrariée en regardant les filles. Xola rougit. Elle ne s'attendait pas à ce que son professeur l'entende.

"Xola, qu'as-tu appris?" demanda le professeur. "Que les anciens ont épuisé toutes les ressources de la planète Terrienne et sont ensuite morts?" demanda-t-elle prudemment. "Non. Ils ont rendu le climat chaud et ce n'étaient pas les gens, c'étaient les ordinateurs et les machines. Et c'est la planète Terre, pas la planète Terrienne," ajouta une autre fille nommée Lin. Xola acquiesça. Avec un soupçon de fierté, le professeur sourit et acquiesça. "Vous avez toutes les deux raison. Savez-vous pourquoi cela s'est passé?" "Parce que les gens étaient à courte vue et avides?" demanda Xola. "Les gens ne pouvaient pas arrêter leurs machines !" s'exclama Lin.

"Encore une fois, vous avez toutes les deux raison," décida le professeur, "mais c'est bien plus compliqué que cela. La plupart des gens à l'époque n'étaient pas conscients de ce qui se passait. Certains ont vu les changements drastiques, mais ne pouvaient pas les inverser. Le morceau le plus célèbre de cette période est un poème d'un auteur anonyme. Il capture le mieux ce qui s'est passé à cette époque. Écoutez bien !"

Le professeur débuta le poème. Une douzaine de petits drones se reposionnèrent devant les enfants et projetèrent la vidéo directement dans leurs yeux. Elle montrait une personne en costume debout dans une forêt constituée seulement de souches d'arbres. Il commença à parler :

*Les machines calculent ; les machines prédisent.*

*Nous marchons comme si nous en faisions partie.*

*Nous cherchons un optimum comme formés.*

*L'optimum est unidimensionnel, local et non contraint.*


*Silicium et chair, à la poursuite de l'exponentialité.*

*La croissance est notre mentalité.*

*Quand toutes les récompenses sont collectées,*

*et les effets secondaires négligés ;*

*Quand toutes les pièces sont minées,*

*et que la nature est laissée pour compte ;*

*Nous serons en difficulté,*

*Après tout, la croissance exponentielle est une bulle.*


*La tragédie des communs se déroule,*

*Explose,*

*Devant nos yeux.*


*Calculs froids et cupidité glaciale,*

*Remplissent la terre de chaleur.*

*Tout meurt,*

*Et nous nous conformons.*


*Comme des chevaux avec des œillères, nous courons la course de notre propre création,*

*Vers le Grand Filtre de la civilisation.*

*Et ainsi nous marchons sans relâche.*

*Comme si nous faisions partie de la machine.*

*Embrassant l'entropie.*

"Un sombre souvenir," dit le professeur pour briser le silence dans la salle. "Il sera téléchargé dans votre bibliothèque. Votre devoir est de le mémoriser jusqu'à la semaine prochaine." Xola soupira. Elle réussit à attraper l'un des petits drones. Le drone était chaud à cause du CPU et des moteurs. Xola aimait la façon dont il réchauffait ses mains.

<!--
"History is boring," Xola whispered to her friend.
Xola, a blue-haired girl, was lazily chasing one of the projector drones humming in the room with her left hand.
"History is important," the teacher said with an upset voice, looking at the girls.
Xola blushed.
She did not expect her teacher to overhear her.

"Xola, what did you just learn?" the teacher asked her. 
"That the ancient people used up all resources from Earther Planet and then died?" she asked carefully.
"No. They made the climate hot and it wasn't people, it was computers and machines. And it's Planet Earth, not Earther Planet," added another girl named Lin.
Xola nodded in agreement.
With a touch of pride, the teacher smiled and nodded.
"You are both right. Do you know why it happened?" 
"Because people were short-sighted and greedy?" Xola asked.
"People could not stop their machines!" Lin blurted out.

"Again, you are both right," the teacher decided,
"but it's much more complicated than that.
Most people at the time were not aware of what was happening.
Some saw the drastic changes, but could not reverse them.
The most famous piece from this period is a poem by an anonymous author.
It best captures what happened at that time.
Listen carefully!"


The teacher started the poem.
A dozen of the small drones repositioned themselves in front of the children and began to project the video directly into their eyes.
It showed a person in a suit standing in a forest with only tree stumps left.
He began to talk:

*The machines compute; the machines predict.* 

*We march on as we are part of it.* 

*We chase an optimum as trained.* 

*The optimum is one-dimensional, local and unconstrained.* 


*Silicon and flesh, chasing exponentiality.* 

*Growth is our mentality.* 

*When all rewards are collected,* 

*and side-effects neglected;* 

*When all the coins are mined,* 

*and nature has fallen behind;* 

*We will be in trouble,* 

*After all, exponential growth is a bubble.* 


*The tragedy of the commons unfolding,* 

*Exploding,*

*Before our eyes.* 


*Cold calculations and icy greed,* 

*Fill the earth with heat.* 

*Everything is dying,* 

*And we are complying.* 


*Like horses with blinders we race the race of our own creation,*

*Towards the Great Filter of civilization.*

*And so we march on relentlessly.*

*As we are part of the machine.*

*Embracing entropy.*

"A dark memory," the teacher said to break the silence in the room.
"It will be uploaded to your library.
Your homework is to memorise it until next week."
Xola sighed.
She managed to catch one of the little drones.
The drone was warm from the CPU and the engines.
Xola liked how it warmed her hands.
-->
