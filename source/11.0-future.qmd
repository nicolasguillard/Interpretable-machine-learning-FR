# Chapitre 11 - Un regard dans la boule de cristal

What is the future of interpretable machine learning?
This chapter is a speculative mental exercise and a subjective guess how interpretable machine learning will develop.
I opened the book with rather pessimistic [short stories](#storytime) and would like to conclude with a more optimistic outlook. 

I have based my "predictions" on three premises:

1. **Digitization: Any (interesting) information will be digitized.**
Think of electronic cash and online transactions. 
Think of e-books, music and videos. 
Think of all the sensory data about our environment, our human behavior, industrial production processes and so on.
The drivers of the digitization of everything are: Cheap computers/sensors/storage, scaling effects (winner takes it all), new business models, modular value chains, cost pressure and much more.
1. **Automation: When a task can be automated and the cost of automation is lower than the cost of performing the task over time, the task will be automated.**
Even before the introduction of the computer we had a certain degree of automation.
For example, the weaving machine automated weaving or the steam machine automated horsepower.
But computers and digitization take automation to the next level. 
Simply the fact that you can program for-loops, write Excel macros, automate e-mail responses, and so on, show how much an individual can automate. 
Ticket machines automate the purchase of train tickets (no cashier needed any longer), washing machines automate laundry, standing orders automate payment transactions and so on.
Automating tasks frees up time and money, so there is a huge economic and personal incentive to automate things.
We are currently observing the automation of language translation, driving and, to a small degree, even scientific discovery. 
1. **Misspecification: We are not able to perfectly specify a goal with all its constraints.**
Think of the genie in a bottle that always takes your wishes literally:
"I want to be the richest person in the world!" -> You become the richest person, but as a side effect the currency you hold crashes due to inflation.  
"I want to be happy for the rest of my life!" -> The next 5 minutes you feel very happy, then the genie kills you.  
"I wish for world peace!" -> The genie kills all humans.  
We specify goals incorrectly, either because we do not know all the constraints or because we cannot measure them. 
Let's look at corporations as an example of imperfect goal specification.
A corporation has the simple goal of earning money for its shareholders.
But this specification does not capture the true goal with all its constraints that we really strive for:
For example, we do not appreciate a company killing people to make money, poisoning rivers, or simply printing its own money. 
We have invented laws, regulations, sanctions, compliance procedures, labor unions and more to patch up the imperfect goal specification.
Another example that you can experience for yourself is
[Paperclips](http://www.decisionproblem.com/paperclips/index2.html), a game in which you play a machine with the goal of producing as many paperclips as possible.
WARNING: It is addictive.
I do not want to spoil it too much, but let's say things get out of control really fast.
In machine learning, the imperfections in the goal specification come from imperfect data abstractions (biased populations, measurement errors, ...), unconstrained loss functions, lack of knowledge of the constraints, shifting of the distribution between training and application data and much more. 

Digitization is driving automation. 
Imperfect goal specification conflicts with automation.
I claim that this conflict is mediated partially by interpretation methods.

The stage for our predictions is set, the crystal ball is ready, now we look at where the field could go!
